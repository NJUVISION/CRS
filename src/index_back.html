<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
<meta http-equiv="x-ua-compatible" content="ie=edge">

<title>Decoder-side Cross Resolution Synthesis for Video Compression Enhancement</title>

<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- <base href="/"> -->

<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
<link rel="icon" type="image/png" href="img/lens-icon.png">
<!-- Place favicon.ico in the root directory -->

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
<link rel="stylesheet" href="css/app.css">

<link rel="stylesheet" href="css/bootstrap.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131406202-2"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-131406202-2');
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Decoder-side Cross Resolution Synthesis for
                    <br>Video Compression Enhancement<br> 
                <!-- <small>
                    <a href="https://vision.nju.edu.cn/">
                    Vision Lab, Nanjing University
                    </a>
                </small> -->
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://lumingzzz.github.io/">
                            Ming Lu
                        </a> <sup>1</sup>
                    </li>
                    <li>
                        <a href="https://tongxyh.github.io/">
                            Tong Chen
                        </a> <sup>1</sup>
                    </li>
                    <li>
                        <a href="">
                            Zhenyu Dai
                        </a> <sup>2</sup>
                    </li>
                    <li>
                        <a href="">
                            Dong Wang
                        </a> <sup>2</sup>
                    </li>
                    <li>
                        <a href="">
                            Dandan Ding    
                        </a> <sup>3</sup>
                    </li>
                    <li>
                        <a href="https://vision.nju.edu.cn/fc/d3/c29470a457939/page.htm">
                            Zhan Ma
                        </a> <sup>1</sup>
                    </li>
                    <!-- <body>
                    </body> -->
                </ul>
            </div>
        </div>

        <div class="affiliations">
            <sup>1</sup> Nanjing University &nbsp;&nbsp;&nbsp;&nbsp;
            <sup>2</sup> OPPO &nbsp;&nbsp;&nbsp;&nbsp;
            <sup>3</sup> Hangzhou Normal University &nbsp;&nbsp;&nbsp;&nbsp;  
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!--<img src="images/pami.jpg" class="img-responsive" alt="overview"><br>
                <div align="center">
                    <img src="images/0.gif" height="222"/><img src="images/1.gif" height="222"/><br><img src="images/2.gif" height="160"/><img src="images/3.gif" height="160"/>  
                </div>-->
                <br />
                <div align="center">
                    <img src="src/pipeline.png" height="195"/>
                </div>
                <body align="center">
                    <strong>CRS-based Video Compression Enhancement (VCE).</strong> &#8595 (in red) is for bicubic down-sampling; <strong>E</strong>, <strong>D</strong>, and 
                    <strong>B</strong> represent video encoder, decoder, and decoded picture buffer (DPB) respectively.
                </body><br>
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    This paper proposes a decoder-side Cross Resolution Synthesis (CRS) module to pursue better compression efficiency beyond the latest Versatile Video Coding (VVC),
                    where we encode intra frames at original high resolution (HR),  compress inter frames at a lower resolution (LR), and then super-resolve decoded LR inter frames 
                    with the help from preceding HR intra and neighboring LR inter frames. For a LR inter frame, a motion alignment and aggregation network (MAN) is devised to 
                    produce temporally aggregated motion representation (AMR) for the guarantee of temporal smoothness; Another texture compensation network (TCN) inputs decoded HR 
                    intra frame, re-sampled HR intra frame, and this LR inter frame to generate multiscale affinity map (MAM) and multiscale texture representation (MTR)  for better 
                    augmenting spatial details; Finally, similarity-driven fusion synthesizes AMR, MTR, MAM to upscale LR inter frame for the removal of compression and resolution 
                    re-sampling noises. We enhance the VVC using proposed CRS, showing averaged 8.76% and 11.93% Bjøntegaard Delta Rate (BD-Rate) gains against the latest VVC anchor 
                    in Random Access (RA) and Low-delay P (LDP) settings respectively. In addition, experimental comparisons to the state-of-the-art super-resolution (SR) based VVC 
                    enhancement methods, and ablation studies are conducted to further report superior efficiency and generalization of proposed algorithm.
                </p>
                <!-- <br />
                <div align="center">
                    <img src="src/crs.png" height="195"/>
                </div>
                <body align="center">
                    <strong>The CRS Model</strong> is comprised of three modular components: a motion alignment and aggregation network (MAN) for generating aggregated motion representation 
                    (AMR), a texture compensation network (TCN) is for fine-grained multiscale texture representation (MTR) and corresponding multiscale affinity map (MAM), and a 
                    similarity-driven fusion to super-resolve input LR inter frame by intelligently combining outputs from the MAN and TCN. &#8595 and &#8593 (in red) are 
                    bicubic filter for downsampling and upsampling.
                </body><br> -->
                <!-- <br />
                <div align="center">
                    <img src="src/mfmc.png" height="195"/>
                </div>
                <body align="center">
                    <strong>Motion Alignment and Aggregation Network (MAN)</strong> for deriving aggregated motion representation (AMR). It consists of two stages: Alignment and Aggregation. 
                    At Alignment stage, 4 residual blocks are utilized to extract deep representative features of each LR inter frames; A multiscale network (MSN) is employed to generate 
                    the multiscale temporal offsets by traversing all pairs of current LR inter frame and each frame in temporal window buffer; Later, a deformable convolution network (DCN) 
                    is applied to generate aligned temporal features by inputting deep features of a neighbor frame and corresponding multiscale temporal offsets derived between this neighbor 
                    frame and current frame. Finally, separable temporal attention (TA) and spatial attention (SA) are consecutively applied to aggregate necessary and useful temporal motion 
                    features for temporally-smooth super-resolution. $T$ is the total number of frames in temporal window buffer used for temporal alignment; $T$ = 2$M$+1 and it is 3 when 
                    having $M$ = 1 in our implementation.
                </body><br>
                <br />
                <div align="center">
                    <img src="src/ttn.png" height="390"/>
                </div>
                <body align="center">
                    {\bf Texture Compensation Network (TCN)} for producing multiscale texture representation (MTR) and multiscale affinity map (MAM). ${\downarrow}{\uparrow}$ (in red) denotes 
                    the re-sampling operation, \textbf{U($d$)} is for unfolding with stride $d$, \textbf{R} is for reshaping operation, {\bf S} is index selection for patch re-organization, 
                    {\bf I} is for interpolation, and \textbf{F($d$)} is for folding operation with stride $d$, which is the inverse operation of \textbf{U($d$)}. The kernel sizes for 
                    \textbf{F(1)}, \textbf{F(2)} and \textbf{F(4)} are $3\times3$, $6\times6$ and $12\times12$ respectively.
                </body><br>
                <br />
                <div align="center">
                    <img src="src/fusion.png" height="195"/>
                </div>
                <body align="center">
                    {\bf Similarity-driven Fusion} for final reconstruction synthesis. Scale-dependent fusion is applied to progressively combine affinity map, multiscale texture 
                    representation (MTR) and aggregated motion representation (AMR) for fine-grained spatiotemporal loss recovery.
                </body><br> -->
            </div>
        </div>

        
        
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2 text-center">
                <h3>
                    
                </h3>
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://arxiv.org/abs/1909.13051">
                        <img src="images/paper.jpg" height="120px"><br>
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="http://yun.nju.edu.cn/f/2c34ad8492/?raw=1">
                        <img src="images/youtube_icon_dark.png" height="120px"><br>
                            <h4><strong>Video Demo</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/NJUVISION/AWnet">
                        <img src="images/github_pad.png" height="120px"><br>
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div> -->

        <!-- <div class="section citation", id="citation">
            <h2>Citation</h2>
            <div class="section bibtex">
              <pre>@InProceedings{chan2021glean,
                    author = {Chan, Kelvin CK and Wang, Xintao and Xu, Xiangyu and Gu, Jinwei and Loy, Chen Change},
                    title = {GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution},
                    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
                    year = {2021}
              </pre>
            </div>
          </div> -->

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3 align="left">
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1" align="left">
                    <div class="CodeMirror cm-s-default CodeMirror-wrap">
                        <div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 4px; left: 4px;">
                            <textarea autocorrect="off" autocapitalize="off" spellcheck="false" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;" tabindex="0">
                            </textarea>
                        </div>
                        <div class="CodeMirror-vscrollbar" cm-not-content="true"><div style="min-width: 1px; height: 0px;">
                        </div>
                    </div>
                    <div class="CodeMirror-hscrollbar" cm-not-content="true">
                        <div style="height: 100%; min-height: 1px; width: 0px;">
                        </div>
                     </div>
                        <div class="CodeMirror-scrollbar-filler" cm-not-content="true">
                        </div>
                        <div class="CodeMirror-gutter-filler" cm-not-content="true">
                        </div>
                        <div class="CodeMirror-scroll">
                            <div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: -17px; border-right-width: 13px; min-height: 100px; padding-right: 0px; padding-bottom: 0px;">
                                <div style="position: relative; top: 0px;">
                                    <div class="CodeMirror-lines">
                                        <div style="position: relative; outline: none;">
                                            <div class="CodeMirror-measure"><span><span>​</span>x</span></div>
                                            <div class="CodeMirror-measure"></div>
                                            <div style="position: relative; z-index: 1;"></div>
                                            <div class="CodeMirror-cursors">
                                                <div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 16.6667px;">&nbsp;</div></div>
                                            <div class="CodeMirror-code" style=""><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">@article{cheng2019dual,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> title={A Dual Camera System for High Spatiotemporal Resolution Video Acquisition},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> author={Cheng, Ming and Ma, Zhan and Asif, M Salman and Xu, Yiling and Liu, Haojie and Bao, Wenbo and Sun, Jun},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> journal={arXiv preprint arXiv:1909.13051},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">    year={2019},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 13px; width: 1px; top: 100px;"></div><div class="CodeMirror-gutters" style="display: none; height: 188px;"></div>
                        <body>
                            Correspondence: Ming Lu (luming@smail.nju.edu.cn)
                        </body>
                        </div>
                    </div>
                </div>
            </div>
        </div> -->
    </div>
</body></html>
